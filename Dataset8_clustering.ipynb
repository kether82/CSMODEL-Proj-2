{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Import\n",
    "Import **pandas** and **matplotlib**."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "\r\n",
    "%load_ext autoreload\r\n",
    "%autoreload 2"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Creating Clusters in Dataset 8 using k-Means Algorithm"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Import the `KMeans` class."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from kmeans import KMeans_py"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dataset 8\n",
    "For this notebook, we will work on dataset 8. The group decided to assume that this is a clustering dataset. This decision was based on a number of factors. First, there is a class variable. The presence of a class variable suggests that the observations have some kind of classifications and are trying to be grouped in some way. Second, the values are continuous. Continuous values rule out the possibility that these are item counts; which in turn makes it unlikely to be a rule mining dataset. The granularity of the values, which goes up to 5 decimal places, hints that it is not some sort of user rating either. This is further supported by the presence of negative values which rules out the possibility of implicitly generated ratings.\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "If you view the `.csv` file in Excel, you can see that our dataset contains 900 **observations** (rows) across 10 **variables** (columns). The following are our assumptions of what each variable in the dataset represents:\n",
    "\n",
    "- **`f1`**: Hip Hop\n",
    "- **`f2`**: R&B\n",
    "- **`f3`**: Jazz\n",
    "- **`f4`**: Rock\n",
    "- **`f5`**: K-Pop\n",
    "- **`f6`**: Country\n",
    "- **`f7`**: Heavy metal\n",
    "- **`f8`**: EDM\n",
    "- **`f9`**: Blues\n",
    "- **`f10`**: Pop\n",
    "- **`class`**: `0` represents songs released in the 1990's, `1` for songs released in the 2000's, and `2` for songs released in the 2010's"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "For this dataset, we will assume that each observation represents a song. For the variables, we will be assuming that each one of them is a genre and the values are system generated valued that represent how \"close\" they are to that specific genre (i.e. a higher value under f4 means that it has many of the features of a rock song). "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### EDA"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let us read the dataset."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dataset_df = pd.read_csv('Dataset8.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let us display the general `info` of the dataset"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dataset_df.info()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let us rename the columns"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dataset_df = dataset_df.rename(columns={\r\n",
    "    'f1': 'Hip Hop',\r\n",
    "    'f2': 'R&B',\r\n",
    "    'f3': 'Jazz',\r\n",
    "    'f4': 'Rock',\r\n",
    "    'f5': 'K-Pop',\r\n",
    "    'f6': 'Country',\r\n",
    "    'f7': 'Heavy Metal',\r\n",
    "    'f8': 'EDM',\r\n",
    "    'f9': 'Blues',\r\n",
    "    'f10': 'Pop'\r\n",
    "})\r\n",
    "dataset_df.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Question 1: Which genre's features is on average the most used in songs?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let us take only the necessary columns for this question."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "ave_df = dataset_df.drop(columns=dataset_df.columns[0]).drop(['class'], axis=1)\r\n",
    "ave_df"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we take the average of each column."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "ave_df = ave_df.mean()\r\n",
    "ave_df"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let us plot the data into a bar plot."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "ave_df.plot.bar()\r\n",
    "plt.xlabel('Genre')\r\n",
    "plt.ylabel('Value')\r\n",
    "plt.title('Average Genre Likeness Value')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "It appears that the features from Pop songs are most common on average."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Question 2: Which genres are correlated?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let us drop irrelevant data from the dataset"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dropped = dataset_df.drop(columns=['Unnamed: 0','class'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let us get and visualize the correlation matrix"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "corr = dropped.corr()\r\n",
    "corr.style.background_gradient(cmap=\"coolwarm\", axis=None).set_precision(2)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "It seems that there are no genres that are correlated"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Clustering"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let us proceed to finding the number of observation per group prior to clustering"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(\"Class 1 : \" , dataset_df.loc[dataset_df['class'] == 0].count().loc['class'])\r\n",
    "print(\"Class 2 : \" , dataset_df.loc[dataset_df['class'] == 1].count().loc['class'])\r\n",
    "print(\"Class 3 : \" , dataset_df.loc[dataset_df['class'] == 2].count().loc['class'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Import required packages\r\n",
    "from sklearn.cluster import KMeans\r\n",
    "sse = []\r\n",
    "list_k = range(1,10)\r\n",
    "for k in list_k:\r\n",
    "    km = KMeans(n_clusters = k)\r\n",
    "    km = km.fit(dataset_df)\r\n",
    "    sse.append(km.inertia_)\r\n",
    "\r\n",
    "plt.plot(list_k, sse, 'b*-')\r\n",
    "plt.xlabel('k')\r\n",
    "plt.ylabel('Sum_of_squared_distances')\r\n",
    "plt.title('Elbow Method For Optimal k')\r\n",
    "plt.show()\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "From the elbow method, we can see that the optimal k is 3."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Instantiate a `KMeans` object with `k` equal to `3`, `start_var` equal to `1`, `end_var` equal to `5`, `num_observations` equal to `150`, and `data` equal to the `DataFrame` object which represents the dataset. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "kmeans = KMeans_py(3, 1, 11, 900, dataset_df)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Initialize the centroids."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "kmeans.initialize_centroids(dataset_df)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Cluster the dataset."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "groups = kmeans.train(dataset_df, 300)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "cluster_0 = dataset_df.loc[groups == 0]\r\n",
    "cluster_1 = dataset_df.loc[groups == 1]\r\n",
    "cluster_2 = dataset_df.loc[groups == 2]\r\n",
    "\r\n",
    "# print(cluster_0.loc[cluster_0['class'] == 0])\r\n",
    "print('Number of data points in each cluster:')\r\n",
    "print('Cluster 0:')\r\n",
    "print('Class 0:\\t', cluster_0.loc[cluster_0['class'] == 0].shape[0])\r\n",
    "print('Class 1:\\t', cluster_0.loc[cluster_0['class'] == 1].shape[0])\r\n",
    "print('Class 2:\\t', cluster_0.loc[cluster_0['class'] == 2].shape[0])\r\n",
    "print('Cluster 1:')\r\n",
    "print('Class 0:\\t', cluster_1.loc[cluster_1['class'] == 0].shape[0])\r\n",
    "print('Class 1:\\t', cluster_1.loc[cluster_1['class'] == 1].shape[0])\r\n",
    "print('Class 2:\\t', cluster_1.loc[cluster_1['class'] == 2].shape[0])\r\n",
    "print('Cluster 2:')\r\n",
    "print('Class 0:\\t', cluster_2.loc[cluster_2['class'] == 0].shape[0])\r\n",
    "print('Class 1:\\t', cluster_2.loc[cluster_2['class'] == 1].shape[0])\r\n",
    "print('Class 2:\\t', cluster_2.loc[cluster_2['class'] == 2].shape[0])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# syn_new_df = pd.concat([syn_df.iloc[:, 0:2], groups.rename('group')], axis=1)\r\n",
    "# dataset_new_df = pd.concat([dataset_df.iloc[:, 1:11], groups.rename('group')], axis=1)\r\n",
    "# print(dataset_new_df.head(3))\r\n",
    "\r\n",
    "# print(syn_new_df.head(5))\r\n",
    "# fig, axs = plt.subplots(1, 2, figsize=(10,5))\r\n",
    "# fig, axs = plt.subplots(1, 2, figsize=(10,5))\r\n",
    "# axs[0].plot(syn_df.loc[syn_df['class'] == 0, 'x'], syn_df.loc[syn_df['class'] == 0, 'y'], 'r+')\r\n",
    "# axs[0].plot(syn_df.loc[syn_df['class'] == 1, 'x'], syn_df.loc[syn_df['class'] == 1, 'y'], 'g+')\r\n",
    "# axs[0].plot(syn_df.loc[syn_df['class'] == 2, 'x'], syn_df.loc[syn_df['class'] == 2, 'y'], 'b+')\r\n",
    "# axs[0].plot(dataset_df.loc[dataset_df['class'] == 0, 'x'], dataset_df.loc[dataset_df['class'] == 0, 'y'], 'r+')\r\n",
    "# axs[0].plot(dataset_df.loc[dataset_df['class'] == 1, 'x'], dataset_df.loc[dataset_df['class'] == 1, 'y'], 'r+')\r\n",
    "# axs[0].plot(dataset_df.loc[dataset_df['class'] == 2, 'x'], dataset_df.loc[dataset_df['class'] == 2, 'y'], 'r+')\r\n",
    "\r\n",
    "# axs[1].plot(syn_new_df.loc[syn_new_df['group'] == 0, 'x'], syn_new_df.loc[syn_new_df['group'] == 0, 'y'], 'r+')\r\n",
    "# axs[1].plot(syn_new_df.loc[syn_new_df['group'] == 1, 'x'], syn_new_df.loc[syn_new_df['group'] == 1, 'y'], 'g+')\r\n",
    "# axs[1].plot(syn_new_df.loc[syn_new_df['group'] == 2, 'x'], syn_new_df.loc[syn_new_df['group'] == 2, 'y'], 'b+')\r\n",
    "\r\n",
    "# for i in range(len(kmeans.centroids)):\r\n",
    "#     axs[1].plot(kmeans.centroids.iloc[i]['x'], kmeans.centroids.iloc[i]['y'], 'k*', ms=12)\r\n",
    "\r\n",
    "# axs[0].grid()\r\n",
    "# axs[1].grid()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# kmeans = KMeans_py(3, 1, 11, 900, dataset_df)\r\n",
    "# kmeans.initialize_centroids(dataset_df)\r\n",
    "# groups = kmeans.train(dataset_df, 300)\r\n",
    "# cluster_0 = dataset_df.loc[groups == 0]\r\n",
    "# cluster_1 = dataset_df.loc[groups == 1]\r\n",
    "# cluster_2 = dataset_df.loc[groups == 2]\r\n",
    "\r\n",
    "# # print(cluster_0.loc[cluster_0['class'] == 0])\r\n",
    "# print('Number of data points in each cluster:')\r\n",
    "# print('Cluster 0:')\r\n",
    "# print('Class 0:\\t', cluster_0.loc[cluster_0['class'] == 0].shape[0])\r\n",
    "# print('Class 1:\\t', cluster_0.loc[cluster_0['class'] == 1].shape[0])\r\n",
    "# print('Class 2:\\t', cluster_0.loc[cluster_0['class'] == 2].shape[0])\r\n",
    "# print('Cluster 1:')\r\n",
    "# print('Class 0:\\t', cluster_1.loc[cluster_1['class'] == 0].shape[0])\r\n",
    "# print('Class 1:\\t', cluster_1.loc[cluster_1['class'] == 1].shape[0])\r\n",
    "# print('Class 2:\\t', cluster_1.loc[cluster_1['class'] == 2].shape[0])\r\n",
    "# print('Cluster 2:')\r\n",
    "# print('Class 0:\\t', cluster_2.loc[cluster_2['class'] == 0].shape[0])\r\n",
    "# print('Class 1:\\t', cluster_2.loc[cluster_2['class'] == 1].shape[0])\r\n",
    "# print('Class 2:\\t', cluster_2.loc[cluster_2['class'] == 2].shape[0])\r\n",
    "# # print(cluster_2.loc[cluster_2['class'] == 2].shape[0] + cluster_0.loc[cluster_0['class'] == 2].shape[0] + cluster_1.loc[cluster_1['class'] == 2].shape[0])\r\n",
    "# # print(cluster_2.loc[cluster_2['class'] == 0].shape[0] + cluster_0.loc[cluster_0['class'] == 0].shape[0] + cluster_1.loc[cluster_1['class'] == 0].shape[0])\r\n",
    "# # print(cluster_2.loc[cluster_2['class'] == 1].shape[0] + cluster_0.loc[cluster_0['class'] == 1].shape[0] + cluster_1.loc[cluster_1['class'] == 1].shape[0])\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "106-87-98\n",
    "114-121-83\n",
    "80-92-119"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "96eb50e1d44aed467dc8f759cb08c32fbfa9babcf79c554e2d0e5feb04653a10"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}